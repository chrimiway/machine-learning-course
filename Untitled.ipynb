{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5f5e72ec2cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1499\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m557\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "Image.fromarray(X_train[1499].astype('uint8'))\n",
    "Image.fromarray(X_test[557].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 101, 3)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "X_train_path = \"./training/*\"\n",
    "X_test_path = \"./testing/*\"\n",
    "\n",
    "X_train = np.zeros(shape=(1500, 101, 101, 3))\n",
    "for img_path in glob.glob(X_train_path):\n",
    "    image_index = int(img_path.split(\"/\")[-1].split(\".\")[0])\n",
    "    im = Image.open(img_path)\n",
    "    X_train[image_index] = np.array(im)\n",
    "    pass\n",
    "\n",
    "X_test = np.zeros(shape=(558, 101, 101, 3))\n",
    "for img_path in glob.glob(X_test_path):\n",
    "    image_index = int(img_path.split(\"/\")[-1].split(\".\")[0]) - 1500\n",
    "    im = Image.open(img_path)\n",
    "    X_test[image_index] = np.array(im)\n",
    "    pass\n",
    "\n",
    "Y_train = pd.read_csv(\"labels_training.csv\")[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/50\n",
      " 350/1200 [=======>......................] - ETA: 14s - loss: 1.0442 - acc: 0.5714"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-019da2ead317>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m           \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m           \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlr_reducer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m           validation_data = (X_val, Y_val))\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and validation set\n",
    "shuffle = np.arange(len(Y_train))\n",
    "np.random.shuffle(shuffle)\n",
    "X_train_new = X_train[:1200]\n",
    "Y_train_new = Y_train[:1200]\n",
    "X_val = X_train[1200:]\n",
    "Y_val = Y_train[1200:]\n",
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "\n",
    "model.add(Conv2D(24, kernel_size=(3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(24, kernel_size=(3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(16))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=5, restore_best_weights=True)\n",
    "model.fit(X_train_new, Y_train_new,\n",
    "          batch_size=50,\n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          shuffle = True,\n",
    "          callbacks = [lr_reducer],\n",
    "          validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8403907203907203"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y_val.ravel(), y_hat.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1834\n",
    "y_hat_test[x - 1500]\n",
    "index = range(len(y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "answer = pd.DataFrame({\"id\": np.arange(1500, 1500+len(y_hat_test)),\n",
    "              \"score\": y_hat_test.ravel()})\n",
    "answer.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 21s 17ms/step - loss: 0.7749 - acc: 0.6167 - val_loss: 0.7348 - val_acc: 0.6500\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.3513 - acc: 0.8700 - val_loss: 0.5105 - val_acc: 0.7633\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1960 - acc: 0.9650 - val_loss: 0.6057 - val_acc: 0.7400\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1255 - acc: 0.9933 - val_loss: 0.4730 - val_acc: 0.8067\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0862 - acc: 0.9992 - val_loss: 0.5422 - val_acc: 0.7567\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0640 - acc: 0.9992 - val_loss: 0.4593 - val_acc: 0.7867\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0506 - acc: 0.9992 - val_loss: 0.4756 - val_acc: 0.7833\n",
      "Epoch 8/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0395 - acc: 0.9992 - val_loss: 0.4692 - val_acc: 0.7933\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 20s 16ms/step - loss: 0.9636 - acc: 0.5417 - val_loss: 1.5282 - val_acc: 0.4700\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.4970 - acc: 0.8008 - val_loss: 0.4720 - val_acc: 0.8033\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.3191 - acc: 0.9300 - val_loss: 0.8182 - val_acc: 0.6533\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.2220 - acc: 0.9792 - val_loss: 0.4815 - val_acc: 0.8100\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 20s 17ms/step - loss: 0.5277 - acc: 0.7392 - val_loss: 0.4237 - val_acc: 0.8067\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.2748 - acc: 0.9167 - val_loss: 0.4604 - val_acc: 0.7867\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1693 - acc: 0.9750 - val_loss: 0.4514 - val_acc: 0.7867\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 20s 17ms/step - loss: 0.5455 - acc: 0.7175 - val_loss: 0.8686 - val_acc: 0.5700\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.2807 - acc: 0.9225 - val_loss: 0.4279 - val_acc: 0.8167\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1564 - acc: 0.9867 - val_loss: 0.4280 - val_acc: 0.8367\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0981 - acc: 0.9967 - val_loss: 0.4741 - val_acc: 0.7567\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 20s 17ms/step - loss: 0.6513 - acc: 0.6625 - val_loss: 1.2788 - val_acc: 0.4833\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.3216 - acc: 0.9042 - val_loss: 0.6521 - val_acc: 0.6900\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.2061 - acc: 0.9750 - val_loss: 0.4386 - val_acc: 0.8400\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1391 - acc: 0.9958 - val_loss: 0.4244 - val_acc: 0.8300\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1035 - acc: 0.9992 - val_loss: 0.4117 - val_acc: 0.8367\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0753 - acc: 0.9992 - val_loss: 0.4168 - val_acc: 0.8267\n",
      "Epoch 7/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0584 - acc: 1.0000 - val_loss: 0.4188 - val_acc: 0.8333\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 20s 17ms/step - loss: 0.5644 - acc: 0.7300 - val_loss: 0.4899 - val_acc: 0.7733\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.2763 - acc: 0.9250 - val_loss: 0.4516 - val_acc: 0.7933\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1561 - acc: 0.9867 - val_loss: 0.5452 - val_acc: 0.7133\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0962 - acc: 0.9967 - val_loss: 0.4903 - val_acc: 0.7533\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 20s 17ms/step - loss: 0.5583 - acc: 0.7042 - val_loss: 0.4804 - val_acc: 0.7900\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.2744 - acc: 0.9333 - val_loss: 0.6022 - val_acc: 0.7100\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1620 - acc: 0.9825 - val_loss: 0.4210 - val_acc: 0.8400\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1105 - acc: 0.9967 - val_loss: 0.4272 - val_acc: 0.8267\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0733 - acc: 1.0000 - val_loss: 0.4369 - val_acc: 0.7967\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 21s 17ms/step - loss: 0.5489 - acc: 0.7133 - val_loss: 0.5135 - val_acc: 0.7533\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.2842 - acc: 0.9225 - val_loss: 0.5628 - val_acc: 0.7433\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1829 - acc: 0.9792 - val_loss: 0.4603 - val_acc: 0.7867\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1125 - acc: 0.9942 - val_loss: 0.5639 - val_acc: 0.7233\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0748 - acc: 0.9967 - val_loss: 0.4759 - val_acc: 0.7733\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 22s 18ms/step - loss: 0.5457 - acc: 0.7308 - val_loss: 0.8997 - val_acc: 0.5567\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.2519 - acc: 0.9342 - val_loss: 0.4455 - val_acc: 0.7967\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.1461 - acc: 0.9900 - val_loss: 0.4443 - val_acc: 0.7933\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0935 - acc: 0.9967 - val_loss: 0.4177 - val_acc: 0.8233\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0600 - acc: 0.9975 - val_loss: 0.4336 - val_acc: 0.8167\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0451 - acc: 0.9975 - val_loss: 0.4446 - val_acc: 0.8067\n",
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "1200/1200 [==============================] - 21s 18ms/step - loss: 0.6135 - acc: 0.6825 - val_loss: 0.7219 - val_acc: 0.6700\n",
      "Epoch 2/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.3115 - acc: 0.9125 - val_loss: 0.4903 - val_acc: 0.7733\n",
      "Epoch 3/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1836 - acc: 0.9750 - val_loss: 0.4580 - val_acc: 0.7900\n",
      "Epoch 4/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.1157 - acc: 0.9967 - val_loss: 0.4443 - val_acc: 0.8067\n",
      "Epoch 5/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0778 - acc: 0.9992 - val_loss: 0.4955 - val_acc: 0.7800\n",
      "Epoch 6/10\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.0565 - acc: 0.9992 - val_loss: 0.4607 - val_acc: 0.8067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8915750915750916"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ensemble\n",
    "num = 10\n",
    "y_hat_all = np.zeros((num, len(Y_val), 1))\n",
    "model_list = []\n",
    "for i in range(num):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(input_shape=X_train.shape[1:]))\n",
    "    \n",
    "    model.add(Conv2D(24, kernel_size=(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss=keras.losses.binary_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)]\n",
    "    model.fit(X_train_new, Y_train_new,\n",
    "              batch_size=50,\n",
    "              epochs=10,\n",
    "              verbose=1,\n",
    "              shuffle = True,\n",
    "              callbacks = callbacks,\n",
    "              validation_data = (X_val, Y_val))\n",
    "    y_hat_all[i] = model.predict(X_val)\n",
    "    model_list.append(model)\n",
    "y_hat = y_hat_all.sum(axis=0) / num\n",
    "# auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y_val.ravel(), y_hat.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_all = np.zeros((num, len(X_test), 1))\n",
    "for i in range(num):\n",
    "    y_hat_test_all[i] = model_list[i].predict(X_test)\n",
    "    pass\n",
    "y_hat_test = y_hat_test_all.sum(axis=0) / num\n",
    "\n",
    "import pandas as pd\n",
    "answer = pd.DataFrame({\"id\": np.arange(1500, 1500+len(y_hat_test)),\n",
    "              \"score\": y_hat_test.ravel()})\n",
    "answer.to_csv(\"submission_ensemble.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-26097666f30c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'skf' is not defined"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X_train, Y_train):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_input (InputLayer)     (None, 101, 101, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             multiple                  20861480  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 18433     \n",
      "=================================================================\n",
      "Total params: 20,879,913\n",
      "Trainable params: 20,825,385\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.layers import Input\n",
    "#Get back the convolutional part of a VGG network trained on ImageNet\n",
    "model_conv = keras.applications.xception.Xception(weights='imagenet', include_top=False)\n",
    "# model_conv = keras.applications.nasnet.NASNetLarge(weights='imagenet', include_top=False, input_shape=(101,101, 3))\n",
    "\n",
    "\n",
    "#Create your own input format (here 3x200x200)\n",
    "input = Input(shape=(101,101, 3),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_conv = model_conv(input)\n",
    "\n",
    "#Add the fully-connected layers \n",
    "x = Flatten(name='flatten')(output_conv)\n",
    "x = Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=input, output=x)\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/30\n",
      "1200/1200 [==============================] - 153s 127ms/step - loss: 0.5812 - acc: 0.6458 - val_loss: 1.0220 - val_acc: 0.6967\n",
      "Epoch 2/30\n",
      "1200/1200 [==============================] - 141s 117ms/step - loss: 0.4059 - acc: 0.8250 - val_loss: 0.3116 - val_acc: 0.8633\n",
      "Epoch 3/30\n",
      "1200/1200 [==============================] - 143s 119ms/step - loss: 0.2575 - acc: 0.9283 - val_loss: 0.8530 - val_acc: 0.8100\n",
      "Epoch 4/30\n",
      "1200/1200 [==============================] - 144s 120ms/step - loss: 0.1126 - acc: 0.9592 - val_loss: 0.4179 - val_acc: 0.9100\n",
      "Epoch 5/30\n",
      "1200/1200 [==============================] - 145s 120ms/step - loss: 0.0341 - acc: 0.9942 - val_loss: 0.3235 - val_acc: 0.9300\n",
      "Epoch 6/30\n",
      "1200/1200 [==============================] - 146s 122ms/step - loss: 0.0283 - acc: 0.9917 - val_loss: 0.2681 - val_acc: 0.9433\n",
      "Epoch 7/30\n",
      "1200/1200 [==============================] - 142s 118ms/step - loss: 0.0281 - acc: 0.9917 - val_loss: 0.1658 - val_acc: 0.9533\n",
      "Epoch 8/30\n",
      "1200/1200 [==============================] - 142s 118ms/step - loss: 0.0188 - acc: 0.9942 - val_loss: 0.1340 - val_acc: 0.9633\n",
      "Epoch 9/30\n",
      "1200/1200 [==============================] - 142s 118ms/step - loss: 0.0071 - acc: 0.9967 - val_loss: 0.1348 - val_acc: 0.9633\n",
      "Epoch 10/30\n",
      "1200/1200 [==============================] - 143s 119ms/step - loss: 0.0318 - acc: 0.9933 - val_loss: 0.1607 - val_acc: 0.9600\n",
      "Epoch 11/30\n",
      "1200/1200 [==============================] - 146s 122ms/step - loss: 0.0297 - acc: 0.9950 - val_loss: 0.2070 - val_acc: 0.9433\n",
      "Epoch 12/30\n",
      "1200/1200 [==============================] - 147s 123ms/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.1361 - val_acc: 0.9567\n",
      "Epoch 13/30\n",
      "1200/1200 [==============================] - 150s 125ms/step - loss: 0.0042 - acc: 0.9983 - val_loss: 0.1107 - val_acc: 0.9600\n",
      "Epoch 14/30\n",
      "1200/1200 [==============================] - 150s 125ms/step - loss: 0.0044 - acc: 0.9992 - val_loss: 0.0993 - val_acc: 0.9700\n",
      "Epoch 15/30\n",
      "1200/1200 [==============================] - 156s 130ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0942 - val_acc: 0.9733\n",
      "Epoch 16/30\n",
      "1200/1200 [==============================] - 145s 121ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0962 - val_acc: 0.9733\n",
      "Epoch 17/30\n",
      "1200/1200 [==============================] - 146s 122ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9733\n",
      "Epoch 18/30\n",
      "1200/1200 [==============================] - 145s 121ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 0.9733\n",
      "Epoch 19/30\n",
      "1200/1200 [==============================] - 145s 121ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9767\n",
      "Epoch 20/30\n",
      "1200/1200 [==============================] - 144s 120ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0856 - val_acc: 0.9767\n",
      "Epoch 21/30\n",
      "1200/1200 [==============================] - 145s 121ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0865 - val_acc: 0.9733\n",
      "Epoch 22/30\n",
      "1200/1200 [==============================] - 145s 121ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9767\n",
      "Epoch 23/30\n",
      "1200/1200 [==============================] - 143s 119ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0860 - val_acc: 0.9767\n",
      "Epoch 24/30\n",
      "1200/1200 [==============================] - 142s 118ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0859 - val_acc: 0.9767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17b1a6898>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.001, patience=5, restore_best_weights=True)\n",
    "\n",
    "my_model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "my_model.fit(X_train_new, Y_train_new,\n",
    "              batch_size=32,\n",
    "              epochs=30,\n",
    "              verbose=1,\n",
    "              shuffle = True,\n",
    "              callbacks=[lr_reducer, early_stopper],\n",
    "              validation_data = (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995897435897436"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = my_model.predict(X_val)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y_val.ravel(), y_hat.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_hat_pretrain = my_model.predict(X_test)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "answer = pd.DataFrame({\"id\": np.arange(1500, 1500+len(y_hat_pretrain)),\n",
    "              \"score\": y_hat_pretrain.ravel()})\n",
    "answer.to_csv(\"submission_pre.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save('xception2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "my_model = load_model(\"res50_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging\n",
    "\n",
    "def training(x_train, y_train, x_val, y_val):\n",
    "    #Get back the convolutional part of a VGG network trained on ImageNet\n",
    "    model_conv = keras.applications.xception.Xception(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "    #Create your own input format (here 3x200x200)\n",
    "    input = Input(shape=(101,101, 3),name = 'image_input')\n",
    "\n",
    "    #Use the generated model \n",
    "    output_conv = model_conv(input)\n",
    "\n",
    "    #Add the fully-connected layers \n",
    "    x = Flatten(name='flatten')(output_conv)\n",
    "    x = Dense(1, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "    #Create your own model \n",
    "    my_model = Model(input=input, output=x)\n",
    "    \n",
    "    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=2, min_lr=0.5e-6)\n",
    "    early_stopper = EarlyStopping(min_delta=0.001, patience=5, restore_best_weights=True)\n",
    "\n",
    "    my_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    my_model.fit(x_train, y_train,\n",
    "                  batch_size=32,\n",
    "                  epochs=30,\n",
    "                  verbose=1,\n",
    "                  shuffle = True,\n",
    "                  callbacks=[lr_reducer, early_stopper],\n",
    "                  validation_data = (x_val, y_val))\n",
    "    _, test_acc = my_model.evaluate(x_val, y_val, verbose=0)\n",
    "    return my_model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1350 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "1350/1350 [==============================] - 225s 166ms/step - loss: 0.4713 - acc: 0.7844 - val_loss: 1.0410 - val_acc: 0.8667\n",
      "0 th, test acc: 0.867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_splits = 10\n",
    "scores, members = list(), list()\n",
    "for i in range(n_splits):\n",
    "    # split data\n",
    "    trainX, testX, trainy, testy = train_test_split(X_train, Y_train, test_size=0.10)\n",
    "    # evaluate model\n",
    "    model, test_acc = training(trainX, trainy, testX, testy)\n",
    "    print('{} th, test acc: {:.3}'.format(i, test_acc))\n",
    "    scores.append(test_acc)\n",
    "    members.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated Accuracy 0.867 (0.000)\n"
     ]
    }
   ],
   "source": [
    "# summarize expected performance\n",
    "print('Estimated Accuracy %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995897435897436"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = my_model.predict(X_val)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(Y_val.ravel(), y_hat.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
